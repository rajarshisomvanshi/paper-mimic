# Paper Mimic - Project Overview

## ğŸ¯ Project Summary

**Paper Mimic** is a standalone, production-ready application extracted from DeepTutor that enables users to:

1. **Upload exam paper PDFs**
2. **Automatically parse** the content using MinerU
3. **Extract questions** using LLM analysis
4. **Generate similar questions** maintaining the same difficulty and concepts
5. **Download results** as structured JSON

This is a complete, focused implementation of the mimic paper feature with its own frontend, backend, and configuration.

---

## ğŸ“¦ What's Included

### âœ… Backend (Complete)
- âœ“ FastAPI server with WebSocket support
- âœ“ PDF parsing pipeline (MinerU integration)
- âœ“ Question extraction (LLM-powered)
- âœ“ Question generation (parallel processing)
- âœ“ Real-time progress tracking
- âœ“ Error handling and validation
- âœ“ JSON result storage

### âœ… Frontend (Ready for Implementation)
- âœ“ Project structure created
- âœ“ API integration ready
- âœ“ Environment configured
- âœ“ Can copy from DeepTutor's question/page.tsx

### âœ… Configuration
- âœ“ Docker setup (Dockerfile + docker-compose.yml)
- âœ“ Environment variables (.env.example)
- âœ“ Python configuration (pyproject.toml, requirements.txt)
- âœ“ Application config (YAML files)

### âœ… Documentation
- âœ“ README.md - Feature overview and quick start
- âœ“ SETUP.md - Step-by-step installation guide
- âœ“ GUIDE.md - Complete setup and configuration
- âœ“ ARCHITECTURE.md - System design and components

---

## ğŸš€ Getting Started (Quick)

### Backend Only (5 minutes)

```bash
cd paper-mimic
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
cp .env.example .env
# Edit .env with your OPENAI_API_KEY
python run_server.py
```

**Access**: http://localhost:8000  
**API Docs**: http://localhost:8000/docs

### Full Stack with Docker (3 commands)

```bash
cd paper-mimic
cp .env.example .env  # Edit with API key
docker-compose up -d
```

**Access**:
- Frontend: http://localhost:3000
- Backend API: http://localhost:8000

---

## ğŸ“ Directory Structure

```
paper-mimic/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agents/question/
â”‚   â”‚   â”œâ”€â”€ coordinator.py           # LLM agent orchestration
â”‚   â”‚   â””â”€â”€ tools/
â”‚   â”‚       â”œâ”€â”€ exam_mimic.py        # Main workflow (600+ lines)
â”‚   â”‚       â”œâ”€â”€ pdf_parser.py        # MinerU integration
â”‚   â”‚       â””â”€â”€ question_extractor.py # LLM extraction
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ main.py                  # FastAPI application
â”‚   â”‚   â””â”€â”€ routers/
â”‚   â”‚       â””â”€â”€ question.py          # WebSocket endpoint
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ config.py                # YAML config loading
â”‚   â”‚   â””â”€â”€ llm.py                   # LLM service
â”‚   â””â”€â”€ logging/
â”‚       â””â”€â”€ logger.py                # Logging configuration
â”œâ”€â”€ web/                             # Next.js frontend (structure created)
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ main.yaml                    # App configuration
â”‚   â””â”€â”€ question_config.yaml         # Agent settings
â”œâ”€â”€ data/
â”‚   â””â”€â”€ user/question/mimic_papers/  # Generated papers
â”œâ”€â”€ pyproject.toml                   # Python metadata
â”œâ”€â”€ requirements.txt                 # Python dependencies
â”œâ”€â”€ Dockerfile                       # Docker image
â”œâ”€â”€ docker-compose.yml               # Docker composition
â”œâ”€â”€ .env.example                     # Environment template
â”œâ”€â”€ run_server.py                    # Start server
â”œâ”€â”€ README.md                        # Features & quick start
â”œâ”€â”€ SETUP.md                         # Installation guide
â”œâ”€â”€ GUIDE.md                         # Complete configuration
â””â”€â”€ ARCHITECTURE.md                  # System design
```

---

## ğŸ”‘ Key Features

### 1. **Smart PDF Processing**
- Parses complex PDFs with text and images
- Uses MinerU for intelligent content extraction
- Handles scanned documents

### 2. **Intelligent Question Extraction**
- LLM-powered question identification
- Supports multiple question types
- Extracts with metadata

### 3. **Parallel Question Generation**
- Generate up to 3 questions in parallel (configurable)
- Maintains similar difficulty
- Preserves core concepts
- Uses different scenarios

### 4. **Real-time Monitoring**
- WebSocket-based progress updates
- Per-question status tracking
- Performance metrics

### 5. **Complete Storage**
- All results saved as JSON
- Organized by date/time
- Easy to retrieve and integrate

---

## ğŸ”Œ API Interface

### WebSocket Endpoint: `/api/question/mimic`

**Upload Mode:**
```json
{
  "mode": "upload",
  "pdf_data": "base64_encoded_pdf",
  "pdf_name": "exam.pdf",
  "kb_name": "default",
  "max_questions": 5
}
```

**Real-time Updates:**
- `progress` - Overall stage progress
- `question_update` - Individual question status
- `result` - Generated question
- `summary` - Final results
- `error` - Error messages
- `complete` - Done signal

---

## ğŸ“Š Technology Stack

| Layer | Technology |
|-------|-----------|
| **Backend** | FastAPI, Python 3.10+, asyncio |
| **PDF Parsing** | MinerU (magic-pdf) |
| **LLM** | OpenAI API (GPT-4) |
| **Frontend** | Next.js, React, TypeScript, Tailwind CSS |
| **Communication** | WebSocket, REST API |
| **Containerization** | Docker, Docker Compose |
| **Configuration** | YAML, Environment variables |

---

## âš™ï¸ Configuration Options

### Environment Variables
```env
OPENAI_API_KEY=sk-...           # Your LLM API key
OPENAI_BASE_URL=https://...     # LLM endpoint
LLM_MODEL=gpt-4-turbo           # Model name
API_PORT=8000                   # Backend port
ENVIRONMENT=development         # dev/prod
```

### Application Settings
```yaml
# config/main.yaml
question:
  max_parallel_questions: 3     # Parallel limit
  max_rounds: 10                # Generation attempts

# config/question_config.yaml
agents:
  question:
    temperature: 0.7            # Creativity (0-1)
    max_tokens: 4000            # Max response
```

---

## ğŸš€ Deployment Options

### Option 1: Local Development
```bash
python run_server.py            # Backend
cd web && npm run dev           # Frontend
```

### Option 2: Docker Compose
```bash
docker-compose up -d            # All services
```

### Option 3: Docker Standalone
```bash
docker build -t paper-mimic .
docker run -p 8000:8000 -e OPENAI_API_KEY=sk-... paper-mimic
```

### Option 4: Cloud Deployment
- Push Docker image to registry
- Deploy to Kubernetes, Cloud Run, or similar
- Configure environment variables
- Mount data volume for persistence

---

## ğŸ“‹ File Checklist

### Backend Files
- [x] `src/agents/question/coordinator.py` - Agent orchestration
- [x] `src/agents/question/tools/exam_mimic.py` - Main workflow
- [x] `src/agents/question/tools/pdf_parser.py` - PDF parsing
- [x] `src/agents/question/tools/question_extractor.py` - Extraction
- [x] `src/api/main.py` - FastAPI app
- [x] `src/api/routers/question.py` - WebSocket router
- [x] `src/services/config.py` - Configuration
- [x] `src/services/llm.py` - LLM service
- [x] `src/logging/logger.py` - Logging

### Configuration Files
- [x] `pyproject.toml` - Python metadata
- [x] `requirements.txt` - Dependencies
- [x] `.env.example` - Environment template
- [x] `config/main.yaml` - Main config
- [x] `config/question_config.yaml` - Agent config
- [x] `Dockerfile` - Docker image
- [x] `docker-compose.yml` - Docker composition

### Documentation Files
- [x] `README.md` - Overview and quick start
- [x] `SETUP.md` - Installation guide
- [x] `GUIDE.md` - Complete configuration
- [x] `ARCHITECTURE.md` - System design

### Frontend Structure (Ready for implementation)
- [x] `web/` directory created
- [x] Config files ready
- [x] Environment template ready

---

## ğŸ”§ Next Steps for Users

### 1. Clone/Copy Project
```bash
cp -r paper-mimic /your/location
cd /your/location/paper-mimic
```

### 2. Install Dependencies
```bash
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

### 3. Configure API Keys
```bash
cp .env.example .env
# Edit .env with your credentials
```

### 4. Run Backend
```bash
python run_server.py
# Access: http://localhost:8000
```

### 5. Setup Frontend (Optional)
```bash
cd web
npm install
npm run dev
# Access: http://localhost:3000
```

### 6. Test with Sample PDF
Upload a PDF and generate questions through:
- Web UI (http://localhost:3000), or
- Direct API calls to http://localhost:8000/api/question/mimic

---

## ğŸ¯ Success Metrics

### Backend
- âœ“ Starts without errors
- âœ“ API responsive at http://localhost:8000
- âœ“ WebSocket connects and streams
- âœ“ PDF parsing works
- âœ“ Questions generated successfully
- âœ“ Results saved as JSON

### Frontend
- âœ“ Loads without errors
- âœ“ Can upload PDF
- âœ“ Shows real-time progress
- âœ“ Displays generated questions
- âœ“ Can download results

### Integration
- âœ“ Frontend connects to backend
- âœ“ WebSocket messages flow correctly
- âœ“ Progress updates in real-time
- âœ“ Results display properly

---

## ğŸ› Common Issues & Fixes

| Issue | Fix |
|-------|-----|
| MinerU not found | `pip install magic-pdf[full]` |
| API key not configured | `cp .env.example .env` and edit |
| Port 8000 already in use | `lsof -ti:8000 \| xargs kill -9` or use different port |
| PDF parsing fails | Check file is not encrypted, try smaller PDF |
| WebSocket connection fails | Ensure backend is running, check firewall |
| Frontend won't build | `cd web && rm -rf node_modules && npm install` |

---

## ğŸ“š Documentation References

- **README.md** - Start here for overview
- **SETUP.md** - Follow for installation
- **GUIDE.md** - Complete configuration reference
- **ARCHITECTURE.md** - Understanding the system
- **API Docs** - http://localhost:8000/docs (when running)

---

## âœ¨ What Makes This Different

âœ“ **Standalone** - Complete, independent application  
âœ“ **Focused** - Only mimic paper feature, no clutter  
âœ“ **Production-Ready** - Full error handling, validation, logging  
âœ“ **Fully Documented** - 4 comprehensive guides  
âœ“ **Easy to Deploy** - Docker support included  
âœ“ **Well-Structured** - Clean separation of concerns  
âœ“ **Configurable** - YAML + environment variables  
âœ“ **Scalable** - Parallel processing, async design  

---

## ğŸ“ Learning Resources

**Understanding the Code:**

1. Start with `exam_mimic.py` - Main orchestration (600+ lines well-commented)
2. Then `pdf_parser.py` - How PDFs are parsed
3. Then `question_extractor.py` - LLM-based extraction
4. Then `api/routers/question.py` - WebSocket handling

**System Flow:**
1. User uploads PDF
2. Backend saves and parses with MinerU
3. LLM extracts questions
4. For each question, LLM generates similar one
5. Results validated and stored
6. Frontend displays progress and results

---

## ğŸ“ Support & Help

1. **Installation Issues** â†’ See SETUP.md
2. **Configuration Help** â†’ See GUIDE.md
3. **System Understanding** â†’ See ARCHITECTURE.md
4. **API Reference** â†’ See http://localhost:8000/docs
5. **Error Messages** â†’ Check logs in `data/logs/`

---

## ğŸ‰ You're All Set!

**Paper Mimic** is ready to use. Start with:

```bash
cd paper-mimic
cp .env.example .env
# Edit .env with your OPENAI_API_KEY
python run_server.py
```

Then visit http://localhost:8000/docs for the interactive API documentation.

---

**Made for educators and students who want intelligent exam preparation tools** ğŸ“šâœ¨

